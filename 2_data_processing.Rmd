---
title: "Data processing"
# subtitle: "Data import"
authors: "Michabo Health Science Ltd"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 2
    number_sections: false
link-citations: true
bibliography: references.bib

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Metabolomics data matrices

Metabolomics data are typically analysed as a matrix of intensities where one axis consists of the **samples** that were analysed and the other axis consists of the **features**. The features of interest for this experiment are the *m/z* at a specific retention time (RT).

![Fig 1.3 Feature X sample matrix of intensity](feature_matrix.png){width=400px}
&nbsp;

The entire data processing, from raw mass spectrometry data to a usable omics data matrix for grouping is beyond the scope of this tutorial. Instead, we will work with a few key data matrices undergoing standard metabolomics data processing.

In brief, the following steps were already performed:

1. **Data reduction** - Full scan (MS1) “peak picking”, grouping and any retention time correction performed by XCMS software [@smith2006xcms].
2. **Quality Control (QC) assessment** - for the removal of poor-quality metabolites and samples.
3. **Xenobiotic metabolite filter** - for the removal of metabolites that are either the test substance or biotransformation products of the test substance [@bowen2023simultaneously].
4. **Identification and removal of features** - blank filter and missing value filter by QC (≥ 30% missing values in the QC samples are removed).
5. **Signal-drift and batch-eﬀect correction** - to account for any signal drift or batch eﬀects [@kirwan2013characterising].
6. **Further identification and removal of features** - further filtering of features based on threshold of missing values and relative standard deviation of the features.
7. **Probabilistic Quotient Normalisation (PQN)** - accounts for the dilution of complex biological mixtures - correction factor calculated from the QC samples [@dieterle2006probabilistic; @di2016non].
8. **Missing value imputation** - using k nearest neighbour approach (for multivariate analysis only) [@hrydziuszko2012missing; @di2016non].
9. **Generalised logarithm transform (glog)** – a variance-stabilising transformation that also reduces the weighting of very intense features in multivariate analysis so that they do not over-power less intense features that might still be significant (for multivariate analysis only) [@parsons2007improved; @di2016non].

The mass spectrometry data processing workflow was developed by the University of Birmingham metabolomics research groups and the Phenome Centre Birmingham (PCB). The current implementation uses the R packages [struct](https://bioconductor.org/packages/release/bioc/html/struct.html), 
[structToolbox](https://www.bioconductor.org/packages/release/bioc/html/structToolbox.html), and [pmp](https://bioconductor.org/packages/release/bioc/html/pmp.html) developed by the PCB informatics team [@lloyd2020struct].

The full details of the data processing methods are found in the [supplemental materials of the Cefic MATCHING publication ](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10944399/bin/204_2024_3680_MOESM1_ESM.pdf) [@viant2024demonstrating]. 

The HILIC_POS assay for male rodents was used as an example for this practical with the following relevant data files for the training available on the github site:


* **HILIC_POS_male/1_unfiltered.csv** - unfiltered intensity matrix following step 1
* **HILIC_POS_male/2_filtered.csv** - filtered (both samples and features) intensity matrix following steps 1-6
* **HILIC_POS_male/3_pqn.csv** - PQN normalised intensity matrix following steps 1-7
* **HILIC_POS_male/4_mv_imputed.csv** - missing value imputed intensity matrix following steps 1-8
* **HILIC_POS_male/5_glog.csv** - glog intensity matrix following steps 1-9




## Intensity data matrix


Let’s start with the pre-filtering and pre-normalisation dataset and see what a typical metabolomics data matrix looks like.


```{r root_dir_url, echo=FALSE}
root <- 'https://raw.githubusercontent.com/michabohealthscience/training-fsa/main'
```


```{r root_dir, echo=FALSE}
root <- '.'
```


```{r hilic_pos_intensity_unfiltered}
hilic_pos_all <- read.csv(file.path(root, 'data/HILIC_POS_male/1_unfiltered.csv'))
```

Again, head can be used for a quick check while View can be used to obtain more detail.

The first column refers to the *m/z* and retention time of a feature while the columns are the samples.

Let’s check how many samples and features we have for this data matrix.


```{r hilic_pos_intensity_cols_rows, results = "hold"}
# feature count
feature_c_all = nrow(hilic_pos_all)
# sample count
samp_c_all = ncol(hilic_pos_all)-1

feature_c_all
samp_c_all

```

We can compare this raw data matrix to the filtered data matrix to see how many features have been removed due to the standard processing steps (i.e. steps 1-6)


```{r hilic_pos_intensity_filtered, results = "hold"}
hilic_pos_f <- read.csv(file.path(root, 'data/HILIC_POS_male/2_filtered.csv'))
```

For this tutorial dataset we should find that only 1 sample was discarded (the blank sample - as it is no longer required for further analysis) and a substantial number of the metabolite features have been removed that were deemed not suitable for further analysis.

```{r hilic_pos_intensity_filtered_cols_rows, results = "hold"}

# feature count
feature_c_f = nrow(hilic_pos_f)
# sample count
samp_c_f = ncol(hilic_pos_f)-1


c('All samples:', samp_c_all)
c('Samples removed:', samp_c_all-samp_c_f)
c('Remaining samples:', samp_c_f)

c('All features:', feature_c_all)
c('Features removed:', feature_c_all-feature_c_f)
c('remaining features:', feature_c_f)
```


Now that we have a better understanding of metabolomics data matrices, we can briefly explain the quality assessments before getting started on the statistical analysis.


# References

